{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProcessamentoTextoExcel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRMaBgt3mfo51rHmqe5A7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igomorf/Arquivo_XLSX_Processamento_Texto/blob/main/ProcessamentoTextoExcel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpErBnayA_oE"
      },
      "source": [
        "pip install xlrd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNy2fwaVBImt"
      },
      "source": [
        "pip install openpyxl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUlIllWKBPBP"
      },
      "source": [
        "pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK3sc27_BUAg"
      },
      "source": [
        "!spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM4q3hV3EcEv"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJDaTO0iBbdL"
      },
      "source": [
        "!pip install deplacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "import pkg_resources,imp\n",
        "imp.reload(pkg_resources)\n",
        "import spacy\n",
        "nlp=spacy.load(\"pt_core_news_sm\")\n",
        "from spacy import displacy\n",
        "spacy.prefer_gpu()\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import string\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import xlrd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd_ukUMWFLxX"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjj8KW7xDogE"
      },
      "source": [
        "words = stopwords.words('portuguese')\n",
        "stopwordsNLTK = list (words)\n",
        "print(stopwordsNLTK)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Lr44mgFPv7"
      },
      "source": [
        "from spacy.lang.pt.stop_words import STOP_WORDS\n",
        "#adicionando stopwords ao dicionário\n",
        "STOP_WORDS |= {\"...\",\"mim\",\"sido\",\"etc\", \"tj\", \"com.os\", \"algum\", \"acho\",\" \",\"\\n\",\"uma\",\"para\",\"haver\",\"há\",\"TJ\",\"forma\",\"pela\",\"deve\",\"fica\",\"ficar\",\"quanto\",'de','do','da','dos','no','na','nos','nas','e','com','ou','a','o','em','por','um','uma','uns','umas','os','as','é','para','não','ao','–','pela','que','este','esta','isto','esse','essa','isso','se','nesse','nessa','nisso','nesses','nestes','nestas','nisto','neste','aquele','aquela','aquilo','daquele','daquela', 'daquilo','daqueles','daquelas','nº', 'número','ora','sob','sobre','pelo', 'seu','sua','seus','suas','à','às', 'ser','sendo','pois','já','assim','porém', 'mas','ter','foi','nem','das','como', 'for','estar','está','qual','quando','eis','seja','segundo','cep','cep:','rua','ele','ela','até','tem','tal:','vem','tinha','autor','autora','réu','ré','réus','rés','autores','autoras','agravante','agravado','agravada','agravados','agravadas','esses'}\n",
        "#nlp.Defaults.stop_words |= {\"uma\",\"para\",\"haver\",\"TJ\",\"forma\",\"pela\",\"deve\",\"fica\",\"ficar\",\"quanto\"}\n",
        "stopwords = list (STOP_WORDS)\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGlsUcQ0FXEG"
      },
      "source": [
        "pontuacao = string.punctuation\n",
        "pontuacao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpEnyyl7Fcwk"
      },
      "source": [
        "#Função para limpar stopwords e pontuação\n",
        "def limpa_texto(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        #if token.lemma_ != \"-PRON-\":\n",
        "            #temp = token.lemma_.lower().strip()\n",
        "        #else:\n",
        "        temp = token.lower_\n",
        "        tokens.append(temp)\n",
        "    tokens_limpos = []\n",
        "    for token in tokens:\n",
        "        if token not in stopwords and token not in pontuacao and token not in stopwordsNLTK:\n",
        "            tokens_limpos.append(token)\n",
        "    return tokens_limpos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS4jSLmZFmkg"
      },
      "source": [
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "#df = pd.read_excel(io.StringIO(export.decode('utf-8')))\n",
        "df = pd.read_excel(io.BytesIO(uploaded.get('ds-pesquisa.xlsx'))) #Use o nome do seu arquivo (no exemplo tem 4 colunas e apenas uma aba)\n",
        "excelPuro= io.BytesIO(uploaded.get('ds-pesquisa.xlsx'))\n",
        "excel = pd.read_excel(excelPuro, 'Respostas ao formulário 1') #Use o nome da aba do seu arquivo\n",
        "excel.columns = [\"DataHora\", \"Perg1\", \"Perg2\", \"Perg3\"]\n",
        "\n",
        "lista1 = list(excel['Perg1']+excel['Perg2']+excel['Perg3'])\n",
        "palavras = limpa_texto (', '.join(lista1)) \n",
        "palavras = FreqDist(palavras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-ouA5-LKYtw"
      },
      "source": [
        "palavras.most_common(50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJBLABqhJQfI"
      },
      "source": [
        "wordcloud = WordCloud(stopwords=stopwords, width=800, height=400).generate(', '.join(palavras))\n",
        "fig, ax = plt.subplots(figsize=(20,12))\n",
        "ax.imshow(wordcloud, interpolation='bilinear')\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.imshow(wordcloud);\n",
        "wordcloud.to_file(\"pesquisa_wordcloud.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
